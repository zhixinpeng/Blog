## 散列思想

**散列表用的是数组支持下标随机访问数据的特性，所以散列表其实就是数组的一种拓展，由数组演化而来。可以说，没有数组，就没有散列表**。

假如有 89 名选手参加运动化，编号是 1 到 89，通过编号我们可以很轻松的查找到选手信息，时间复杂度是 O(1)。

如果编码不能这么简单，要加上年级班级信息，比如 051167，那我们如何获取到选手信息呢？我们只要截取最后两位作为数组下标就可以了。

这是典型的散列思想。其中选中的编号叫做**键（key）**或者**关键字**。我们把参赛编号转化为数组下标的映射方法叫做**散列函数（Hash 函数、哈希函数）**，而散列函数计算得到的值就叫做**散列值（Hash值、哈希值）**。

散列表的两个核心问题就是**散列函数设计**和**散列冲突解决**。

![img](https://static001.geekbang.org/resource/image/92/73/92c89a57e21f49d2f14f4424343a2773.jpg)

## 散列函数

散列函数在散列表中起到非常关键的作用。它把 key 转化成 hash(key)，用于在数组中获取值。

该如何构建散列函数呢？有三点设计的基本要求：

- 散列函数计算得到的散列值是一个非负整数
- 如果 key1 = key2，那 hash(key1) = hash(key2)
- 如果 key1 != key2，那 hash(key1) != hash(key2)

第三点要求看起来很合理，但在实际情况下，要找到一个不同 key 对应的散列值不一样的散列函数，几乎是不可能的。这叫做**散列冲突**。

## 散列冲突

再完美的散列函数也无法避免散列冲突。常用的解决方法有两类：

- 开放寻址法（open addressing）

  开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。

  那如何重新探测呢？有个比较简单的探测方法叫**线性探测（Linear Probing）**。

  当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，直到找到空闲位置为止。

  查找元素过程有点类似插入。通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则返回当前下标，否则顺序往后依次查找。如果遍历到数组的空闲位置还没有找到，则说明要查找的元素没有在散列表中。

  对于使用线性探测法解决冲突的散列表，删除操作有些特殊。如果我们本来查找存在的数据被删除了，那之前的查找算法就会失效。应该如何解决这个问题呢？

  我们可以将删除的元素标记为 deleted。当线性探测查找的时候遇到 deleted 标记空间，并不是停下来，而是继续往下探测。。

  综上，你可能已经发现了，线性探测法存在很大的问题。数据越来越多时，冲突的几率会越来越高，空闲位置越来越少，每次查找删除时可能需要探测整张散列表。

  除去线性探测法，还有两种比较经典的探测方法：**二次探测（Quadratic probing）**和**双重散列（Double hashing）**。

  所谓二次探测，跟线性探测很像，不过每次探测的步长变成了原来的二次方。

  所谓双重散列，意思是不仅要使用一个散列函数，而是使用一组散列函数。如果第一个散列函数计算的位置被占用了，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

  不管用哪种探测方法，当散列表中空闲位置不多时，散列冲突的概率就会大大提高。我们用**装载因子**来表示空位的多少

  ```markdown
  散列表的装载因子 = 填入表中的元素个数 / 散列表的长度
  ```

- 链表法（chaining）

  链表法是一种更加常用的散列冲突解决办法。在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

  ![img](https://static001.geekbang.org/resource/image/a4/7f/a4b77d593e4cb76acb2b0689294ec17f.jpg)

  当插入时，找到对应的散列槽位，将其插入到对应链表中即可，插入时间复杂度为 O(1)。

  当查找、删除时，通过散列函数计算出对应的槽，然后遍历链表查找或者删除。时间复杂度和链表的长度 k 有关，也就是 O(k)。对于散列均匀的散列函数来说，k = n / m，n 表示散列表中数据的个数，m 表示散列表中槽的个数。

## 如何设计散列函数

散列函数设计的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能。

- 散列函数的设计不能太复杂
- 散列函数生成的值要尽可能随机并且均匀分布

## 装载因子过大怎么办

针对散列表，当装载因子过大时，可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到新的散列表中。

针对数组的扩容，数据搬移比较简单，但是针对散列表来说，就复杂多了。因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。

因此，当散列表的装载因子超过某个阈值时，就需要进行扩容。装载因子阈值需要选择得当。

## 如何避免低效扩容

如果散列表当前大小为 1GB，如果要扩容为原来的两倍，那就需要对 1GB 的数据重新计算哈希值，并且从原来的散列表搬移到新的散列表。

如果我们的业务代码直接服务用户，尽管大部分情况下，插入一个数据都很快，但是，极个别非常慢的插入操作，也会让用户崩溃。这时候这种“一次性”扩容的机制就不合适了。

为了解决这个问题，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子到达阈值之后，我们只申请新空间，并不将老的数据搬移到新散列表中。当有新数据插入时，插入到新的散列表中，并且从老的散列表中拿出一个数据放入到新散列表。反复这一过程，旧散列表就一点点搬移到新散列表中了。

## 如何选择冲突解决办法

Java 中 LinkedHashMap 采用了链表法解决冲突，ThreadLocalMap 采用了线性探测的开放寻址法来解决冲突。

- **开放寻址法**

  **当数据量比较小、装载因子小的时候，适合采用开放寻址法**

- **链表法**

  **基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表**

## 工业级散列表举例分析

以 Java 中的 HashMap 为例

**1. 初始大小**

HashMap 的初始大小是 16，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容次数，这会大大提高 HashMap 的性能。

**2.装载因子和动态扩容**

最大装载因子默认是 0.75，启动自动扩容，每次扩容为原来的两倍

**3.散列冲突解决办法**

HashMap 底层采用链表法解决冲突。在 JDK1.8 版本中，为了对 HashMap 做进一步优化，引入了红黑树。当链表长度过长（默认为 8）时，链表就转换为红黑树。当红黑树结点个数小于 8 时，又自动转化为链表。

**4.散列函数**

散列函数的设计并不复杂，追求的是简单高效、分布均匀。

```java
int hash(Object key) { int h = key.hashCode()； return (h ^ (h >>> 16)) & (capicity -1); //capicity表示散列表的大小}
```

## LRU 缓存淘汰算法

借助散列表，可以把 LRU 缓存淘汰算法的时间复杂度降低到 O(1)。

回忆一下用链表实现的 LRU 缓存淘汰算法：

因为缓存大小有限，需要淘汰一个数据的时候，直接将链表头部的结点删除。需要缓存某个数据的时候，先在链表中查找，如果没有找到，则直接放在链表尾部，如果找到了，则把它移动到链表的尾部。因为查找需要遍历链表，所以用链表实现的 LRU 缓存淘汰算法时间复杂度为 O(n)。

总结一下，缓存系统的主要操作有：

- 往缓存添加一个数据
- 从缓存中删除一个数据
- 在缓存中查找一个数据

这三个操作都涉及到查找操作，如果单纯使用链表的话，时间复杂度为 O(n)。如果将散列表和链表这两种数据结构结合，可以将这三种操作的时间复杂度降到 O(1)。

![img](https://static001.geekbang.org/resource/image/ea/6e/eaefd5f4028cc7d4cfbb56b24ce8ae6e.jpg)

**前驱和后继指针是为了将结点串在双向链表中，hnxext指针是为了将结点串在散列表的拉链中**。

